{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory = r\"C:\\Users\\Public\\_Data\\Old_HEJP_Data\\Latest_Version\"\n",
    "\n",
    "jobs_table = pd.read_csv(root_directory + r\"\\Main_Data\\Main_Table_01192020.csv\")\n",
    "print(len(jobs_table))\n",
    "NSF_table = pd.read_csv(root_directory + r\"\\Faculty_Data\\Faculty_Table_11222019.csv\")\n",
    "print(len(NSF_table))\n",
    "# skill_table = pd.read_csv(root_directory + r\"\\Skills_Data\\Skill_Table_06072019.csv\")\n",
    "# print(len(skill_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# Visualization (1)\n",
    "# Growth of Job Postings by NSF Field of Study: 2007-2017\n",
    "#########################################################\n",
    "\n",
    "# Only the NSF field table is needed for this visualization since all analysis is \n",
    "# done on faculty postings and their NSF Fields. To isolate the relevant postings \n",
    "# we will need to drop all observatiosn of non-faculty jobs and postdoc students. \n",
    "\n",
    "table = NSF_table[(NSF_table['Faculty']==1)|(NSF_table['Post-Doctoral']==0)]\n",
    "\n",
    "# This function is used to extract the sum of all postings in each NSF field. It \n",
    "# essentially adds the entire table up along its dummy variables while doing some\n",
    "# formating on the result.\n",
    "def extract_fields(df, year, fields):\n",
    "    # Isolate the years\n",
    "    df = df[df['Year']==year]\n",
    "    \n",
    "    # Summation of an indicator attribute gives the number in that category\n",
    "    field_totals = df[fields].sum()\n",
    "    \n",
    "    # Convert into a dataframe\n",
    "    field_totals = pd.DataFrame(field_totals).reset_index()\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    field_totals = field_totals.rename(columns={0:'count'})\n",
    "    \n",
    "    return field_totals\n",
    "    \n",
    "# This attribute list is the set of all NSF fields we care about for the purposes of \n",
    "# this visualization. We omit certain columns because they are uninteresting, because \n",
    "# they will introduce misleading numbers, or simply because they are far too specific. \n",
    "# For example we omit \"Other humanities and arts\" in the Old_HJEP sample due to some \n",
    "# uncertainty regarding how that category is populated by BG. Another example is Health \n",
    "# Sciences. It must also be removed since growth in Health sciences outstrips the \n",
    "# growth of other fields. To emphasisze this fact Health Sciences was given its own set \n",
    "# of visualizations. If instead it were included here, the scale of the graph for other \n",
    "# interesting fields would be hard to read.\n",
    "\n",
    "NSF_fields = ['Agricultural sciences and natural resources', 'Biological and biomedical sciences',\n",
    "               'Chemistry', 'Geosciences, atmospheric, and ocean sciences', 'Physics and astronomy',\n",
    "               'Computer and information sciences', 'Mathematics and statistics', 'Psychology', \n",
    "               'Anthropology', 'Economics', 'Political science and government', 'Sociology', \n",
    "               'Other social sciences', 'FS_Engineering', 'FS_Education',\n",
    "               'Foreign languages and literature', 'History', 'Letters', \n",
    "               'Business management and administration', 'Communication']\n",
    "\n",
    "NSF_07 = extract_fields(table, 2007, NSF_fields)\n",
    "NSF_17 = extract_fields(table, 2017, NSF_fields)\n",
    "\n",
    "# Measure growth between the two years that we extracted\n",
    "def get_growth(df1, df2):\n",
    "    df = df1.merge(df2, on='index')\n",
    "    \n",
    "    df = df[df['count_y'] > 1000]\n",
    "    \n",
    "    df['growth'] = (df['count_y'] - df['count_x'])/df['count_x']\n",
    "    \n",
    "    df = df.sort_values(by='growth').reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "NSF_growth = get_growth(NSF_07, NSF_17)\n",
    "\n",
    "display(NSF_growth)\n",
    "\n",
    "# Graph using matplotlib's pyplot\n",
    "def Graph_NSF(df, title):\n",
    "    \n",
    "    growth = df['growth'].values\n",
    "    \n",
    "    x1 = df['count_x'].values\n",
    "    x2 = df['count_y'].values\n",
    "    \n",
    "    catagories = df['index'].values\n",
    "    \n",
    "    ind = np.arange(len(growth))\n",
    "\n",
    "    for k in range(len(growth)):\n",
    "       # print(growth[k], counts[k,:], ind[k])\n",
    "        plt.annotate(s=str(round(growth[k]*100,1)) + '% Growth', xy=(x2[k]+250, ind[k]))\n",
    "        \n",
    "    width = 0.2\n",
    "    \n",
    "    plt.barh(ind + width, x1, width, label='2007', color='goldenrod')\n",
    "    plt.barh(ind, x2, width, label='2017', color='royalblue')\n",
    "\n",
    "    plt.yticks(ind, catagories)\n",
    "    plt.ylabel('NSF Catagory')\n",
    "    plt.xlabel('Number of Postings')\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(10,10)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "Graph_NSF(NSF_growth, 'Growth of Job Postings by NSF Field: 2007-2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Visualization (2)\n",
    "# All Faculty Openings: 2010-1017\n",
    "# Grouped by Employee type and by institution type\n",
    "##################################################\n",
    "\n",
    "# The years of analysis\n",
    "year1 = 2007\n",
    "year2 = 2017\n",
    "\n",
    "# Again remove the Health sciences faculty, but by a different method. Now we \n",
    "# need to omit the entire field rather than simply ignoring a column. Therefore, \n",
    "# all postings that are marked only as [Health sciences == 1] will be removed. \n",
    "# Note that this does not include postings that are listed in two different \n",
    "# faculty categories. For example a posting listed as \n",
    "# [Health sciences == 1 AND Biological and biomedical sciences == 1] would still \n",
    "# make it into the sample.\n",
    "nsf = NSF_table[((NSF_table['Number of Detailed Fields of Study'] > 1) | (NSF_table['Health sciences'] != 1))]\n",
    "\n",
    "# Only faculty postings\n",
    "nsf = nsf[(nsf['Post-Doctoral']!=1)&(nsf['Faculty']==1)]\n",
    "\n",
    "# Pull in relevant indicator dummies from the Jobs table\n",
    "full = jobs_table[['Job ID', '2-year', '4-year', 'Public', 'Private', 'R1']].merge(nsf, on='Job ID', how='inner')\n",
    "\n",
    "# Restrict the years\n",
    "full = full[(full['Year']==year1)|(full['Year']==year2)]\n",
    "\n",
    "# The institution sectors for which we want to isolate growth\n",
    "sectors = ['All Higher Education', 'Public', 'Private', '4-year', '2-year', 'R1'] \n",
    "\n",
    "def get_sectorwise_counts(df, year, sectors):\n",
    "    df = df[df['Year']==year]\n",
    "    \n",
    "    # Storage place for results\n",
    "    all_sectors = None\n",
    "    \n",
    "    # For each of the relevant sectors, pull out the Tenure_Line, FTC, PTC, \n",
    "    # and contingent sums.\n",
    "    for s in sectors:\n",
    "        if s != 'All Higher Education':\n",
    "            temp = df[df[s]==1]\n",
    "        else:\n",
    "            temp = df\n",
    "\n",
    "        cat_sum = pd.DataFrame(temp[['Tenure_Line', 'Full-time Contingent', 'Part-time Contingent', 'Contingent']].sum())\n",
    "\n",
    "        cat_sum = cat_sum.rename(columns={0:s})\n",
    "        cat_sum = cat_sum.transpose()\n",
    "\n",
    "        if all_sectors is None:\n",
    "            all_sectors = cat_sum\n",
    "        else:\n",
    "            all_sectors = all_sectors.append(cat_sum)\n",
    "\n",
    "    # Perform FTC and PTC sum estimation as detailed in Best Practices Manual\n",
    "    total = all_sectors['Full-time Contingent'] + all_sectors['Part-time Contingent']\n",
    "\n",
    "    ftc_perc = all_sectors['Full-time Contingent']/total\n",
    "    ptc_perc = all_sectors['Part-time Contingent']/total\n",
    "\n",
    "    all_sectors['Full-time Contingent'] = round(all_sectors['Contingent'] * ftc_perc)\n",
    "    all_sectors['Part-time Contingent'] = round(all_sectors['Contingent'] * ptc_perc)\n",
    "    \n",
    "    all_sectors = all_sectors.astype('int').reset_index()\n",
    "\n",
    "    return(all_sectors)   \n",
    "\n",
    "sectors_07 = get_sectorwise_counts(full, year1, sectors)\n",
    "sectors_17 = get_sectorwise_counts(full, year2, sectors)\n",
    "\n",
    "# Graph results using pyplot\n",
    "def graph_sectors(df1, df2):\n",
    "        \n",
    "        ind = np.arange(len(df1))\n",
    "        \n",
    "        labels = df1['index']\n",
    "        \n",
    "        for s in ['Tenure_Line', 'Full-time Contingent', 'Part-time Contingent']:\n",
    "            \n",
    "            x1 = df1[s]\n",
    "            x2 = df2[s]\n",
    "\n",
    "            growth = round((x2-x1)/x1 * 100, 2)\n",
    "            \n",
    "            width = 0.35\n",
    "            fig, ax = plt.subplots(figsize=(12, 10))\n",
    "            \n",
    "            ax.barh(ind+width, x1, width, label=year1, color='royalblue')\n",
    "            ax.barh(ind, x2, width, label=year2, color='gold')\n",
    "            \n",
    "\n",
    "            plt.yticks(ind, labels)\n",
    "            plt.ylabel('Institution Type')\n",
    "            plt.xlabel('Number of Postings')\n",
    "            plt.title(f'Institution Growth for {s} Postings, {year1} to {year2}')\n",
    "\n",
    "            for k in range(len(labels)):\n",
    "                plt.annotate(s=str(round(growth[k],1)) + '% Growth', xy=(x2[k]+250, ind[k]))\n",
    "\n",
    "            plt.legend(loc='upper right')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "graph_sectors(sectors_07, sectors_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# Visualization (3)\n",
    "# Share of faculty vs Non-Faculty Openings: 2007-2017\n",
    "# Group by type of institution\n",
    "#####################################################\n",
    "\n",
    "year1 = 2007\n",
    "year2 = 2017\n",
    "\n",
    "# Remove Health Care inclusing Nursing career area, because of massive growth in\n",
    "# teaching hospitals recently. We believe this growth due to a dispersion of \n",
    "# medical research responsibilites away from from the NIH and into higher ed. If\n",
    "# this is the case, we would not want this endogenous force to influence the\n",
    "# ratios of Faculty and Non-Faulty. Non-faculty would be greatly increased in \n",
    "# institutions that have teaching hospitals. We are interested only in the traditional\n",
    "# university side of the equation for this visual.\n",
    "main = jobs_table[jobs_table['Career Area'] != 'Health Care including Nursing']\n",
    "\n",
    "# Restrict the years\n",
    "main = main[(main['Year'] == year1) | (main['Year'] == year2)]\n",
    "\n",
    "# Create a Job ID mask for removing the post-doc and health sciences exclusive postings\n",
    "temp = NSF_table[NSF_table['Post-Doctoral'] != 1]\n",
    "temp = temp[(temp['Number of Detailed Fields of Study'] > 1) | (temp['Health sciences'] != 1)]\n",
    "mask = temp[['Job ID', 'Faculty']]\n",
    "del(temp)\n",
    "\n",
    "main = main.merge(mask, how='inner')\n",
    "\n",
    "# Graph Data using pyplot\n",
    "def faculty_differences(df, title):\n",
    "    \n",
    "    # This pandas code is old and not very pretty. Pay it no mind...\n",
    "    # It is simply used to isolate the information from the groupby command\n",
    "    # and turn it into iterables that pyplot can work with.\n",
    "    faculty = np.zeros(2)\n",
    "    non_fac = np.zeros(2)\n",
    "    for index, row in df.iterrows():\n",
    "        if row['Year'] == year1:\n",
    "            if row['Faculty'] == 0:\n",
    "                non_fac[0] = row['Job ID']\n",
    "            else:\n",
    "                faculty[0] = row['Job ID']\n",
    "        else:\n",
    "            if row['Faculty'] == 0:\n",
    "                non_fac[1] = row['Job ID']\n",
    "            else:\n",
    "                faculty[1] = row['Job ID']\n",
    "                \n",
    "    years = [year1, year2]\n",
    "    ind = np.array([x for x, _ in enumerate(years)])\n",
    "\n",
    "    total = faculty + non_fac\n",
    "\n",
    "    prop_fac = np.true_divide(faculty, total) * 100\n",
    "    prop_non = np.true_divide(non_fac, total) * 100\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    \n",
    "    ax.bar(ind, prop_fac, width=0.5, label='Faculty', color='deepskyblue', bottom=prop_non)\n",
    "    ax.bar(ind, prop_non, width=0.5, label='Non-Faculty', color='goldenrod')\n",
    "    # plt.bar(ind + 0.5,100, width=0.01, label='', color = 'black')\n",
    "\n",
    "    for k in range(len(ind)):\n",
    "        plt.annotate(s='(' + str(round(prop_fac[k], 1)) + '%)', xy=(ind[k]-0.1, prop_non[k]+0.5*prop_fac[k]))\n",
    "        plt.annotate(s='(' + str(round(prop_non[k], 1)) + '%)', xy=(ind[k]-0.1, 0.5*prop_non[k]))\n",
    "\n",
    "    plt.xticks(ind, years)\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.xlabel('Year')\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.legend(loc='lower center')\n",
    "    plt.show()\n",
    "    \n",
    "# Reuse the same sector list from (2)\n",
    "sectors = ['All Higher Education', 'Public', 'Private', 'R1', '4-year', '2-year']\n",
    "\n",
    "for s in sectors:\n",
    "    if s == 'All Higher Education':\n",
    "        df = main\n",
    "    else:\n",
    "        df = main[main[s]==1]\n",
    "        s = s + ' Institutions'\n",
    "    \n",
    "    # Group data by year and faculty status, count on Job ID to get the number\n",
    "    # of postings in each of those groups.\n",
    "    groups = df.groupby(['Year', 'Faculty']).count()[['Job ID']].reset_index()\n",
    "    \n",
    "    faculty_differences(groups, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
